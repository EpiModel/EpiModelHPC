[{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Using `slurmworkflow` with EpiModel","text":"slurmworkflow package construct workflows SLURM equipped High Performance Computer (HPC). vignette, workflow refers set tasks executed HPC, one . describe construct use workflows using EpiModel/EpiModelHIV-Template project. project uses renv requires access EpiModelHIV-p private repository. vignette assumes project hosted git repository checked local computer HPC. vignette use Rollins School Public Health (RSPH) High Performance Computing cluster (HPC) Emory University example.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"structure-of-an-applied-epimodelhiv-project","dir":"Articles","previous_headings":"","what":"Structure of an Applied EpiModelHIV Project","title":"Using `slurmworkflow` with EpiModel","text":"R scripts located “R/” subdirectory using following naming conventions: “01-snake_case_name.R”: steps run locally given order. “workflow_01-snake_case_names.R”: scripts creating workflow directories sent HPC. “utils-snake_case_name.R”: utility scripts sourced steps workflows. limit code repetition. “data/” directory contains: “data/input/”: files required project code ran. files tracked git. “data/intermediate/”: raw files produced used code. tracked git. “data/output/”: final results, tables, graphs. Tracked git.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"general-steps-in-a-applied-epimodelhiv-project","dir":"Articles","previous_headings":"","what":"General Steps in a Applied EpiModelHIV Project","title":"Using `slurmworkflow` with EpiModel","text":"applied projects aim accurately represent population Men Sex Men (MSM) Atlanta Metro area. simulate HIV epidemic behave different intervention scenarios. (massive) oversimplification project see following 3 steps: Estimate social networks modeling population interactions. Calibrate epidemic model match key epidemiological targets. Run model intervention scenarios assess effects epidemic.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"local-vs-hpc-context","dir":"Articles","previous_headings":"","what":"Local vs HPC Context","title":"Using `slurmworkflow` with EpiModel","text":"numbered scripts (“R/01-snake_case_name.R”) meant executed local computer. allow explore steps substeps small networks replications. define context variable top. variable takes value “local” “hpc” use set context computation: - “local”: Uses small networks replications, unfit publication. used test code processes. - “hpc”: Uses full size networks many replications. used produce analysis publication. code validated locally. lot numbered scripts re-used workflows context variable set “hpc”. goal : scripts run locally, run HPC without modification.","code":""},{"path":[]},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"overview","dir":"Articles","previous_headings":"Network Estimation and Diagnostics","what":"Overview","title":"Using `slurmworkflow` with EpiModel","text":"project simulates HIV dynamics population 100 000 individuals. first step estimate 3 networks 100 000 nodes representing respectively main, casual one partnerships. step happen script “R/01-networks_estimation.R”. Afterwards want diagnose estimations using script “R/02-networks_diagnostics.R” finally explore diagnostics interactively script “R/03-networks_diagnostics_explore.R”. run 3 scripts locally make sure understand . Without modification, context variable set “local” produce fast “Stochastic-Approximation” 5k nodes networks. NOTE: run script fresh R console time avoid starting polluted environment lead complicated debugging. RStudio: Ctrl-Shift-F10 .rs.restartR() (aliased rs() project). : rm(list = ls()) instead, thing used.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"defining-the-networks_estimation-workflow","dir":"Articles","previous_headings":"Network Estimation and Diagnostics","what":"Defining the “networks_estimation” workflow","title":"Using `slurmworkflow` with EpiModel","text":"Now run 3 scripts locally, define HPC workflow run first 2 parts, networks estimation networks diagnostics, 100k nodes networks full MCMLE estimation method. Trying run locally take multiple days probably crash computer ending. Instead, create workflow locally, send HPC, run collect results analysis. script “R/workflow_01-networks_estimation.R” responsible creation first workflow. walk block block understand basics slurmworkflow.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"setup","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Defining the “networks_estimation” workflow","what":"Setup","title":"Using `slurmworkflow` with EpiModel","text":"workflow exists computer directory inside “workflows/” directory project. first workflow called “networks_estimation” live “workflows/networks_estimation/”. First load required libraries source “R/utils-0_project_settings.R”. last script contains variable used throughout project. make sure current_git_branch correct put emai address mail_user. way HPC send mail workflow finished. set max_cores variable 10. number CPU cores used network estimations. 10 usually works fine. “R/utils-hpc_configs.R” script contains helper functions simplify HPC setup. part uncommented using RSPH cluster: use EpiModelHPC::swf_configs_rsph helper function create hpc_configs objects holds pre-defined configurations. specify want work “epimodel” partition e-mails telling us jobs done sent “user@emory.edu”. Note: HPC using Slurm workflow manager allocate tasks computing nodes. EpiModel partition allocate jobs nodes reserved EpiModel team. option preemptable, can use empty node may kicked reserved node preempted someone.","code":"# Libraries -------------------------------------------------------------------- library(\"slurmworkflow\") library(\"EpiModelHPC\")  # Settings --------------------------------------------------------------------- source(\"./R/utils-0_project_settings.R\") max_cores <- 10 source(\"./R/utils-hpc_configs.R\") # creates `hpc_configs` # Must be sourced **AFTER** \"./R/utils-0_project_settings.R\"  hpc_configs <- EpiModelHPC::swf_configs_rsph(   partition = \"epimodel\",   r_version = \"4.2.1\",   mail_user = mail_user )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"creating-the-workflow","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Defining the “networks_estimation” workflow","what":"Creating the workflow","title":"Using `slurmworkflow` with EpiModel","text":"slurmworkflow::create_workflow function takes 2 mandatory arguments: wf_name: name new workflow default_sbatch_opts: list default options sbatch command. shared among steps. created workflow called “networks_estimation” use sbatch options stored hpc_configs$default_sbatch_opts. specifies want use “epimodel” partition e-mail sent task fails. created directory “workflows/networks_estimation” stored summary wf variable. now workflow steps. notes: SLURM configuration can vary, HYAK instance accounting module specify “account” option). equivalent swf_configs_hyak function exists HYAK ecosystem. - default_sbatch_opts sbatch_opts parameters accept options sbatch starting “–”. (e.g. “account” valid “” , corresponds “-” shorthand) - “workflows/networks_estimation” directory already exists, create_workflow throw error. delete previous versions workflow want overwrite .","code":"# Workflow creation ------------------------------------------------------------ wf <- create_workflow(   wf_name = \"networks_estimation\",   default_sbatch_opts = hpc_configs$default_sbatch_opts ) hpc_configs$default_sbatch_opts #> list( #>   \"partition\" = \"epimodel\", #>   \"mail-type\" = \"FAIL\" #>   \"mail-user\" = \"user@emory.edu\" #> )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"adding-of-a-renvrestore-step","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Defining the “networks_estimation” workflow","what":"Adding of a renv::restore Step","title":"Using `slurmworkflow` with EpiModel","text":"running actual calculation, want make sure project HPC date right packages version. translates running git pull HPC renv::restore() project. add step workflow. slurmworkflow::add_workflow_step take 2 mandatory arguments: wf_summary: summary workflow edit (wf variable) step_tmpl: step template. made special kind functions slurmworkflow. also use optional sbatch_opts arguments override default options defined . step template function EpiModelHPC::step_tmpl_renv_restore takes two arguments: git_branch: branch repository must follow. branch followed (HPC) right one, step stop avoid potential data loss undefined behaviors. use current_git_branch variable defined “R/utils-0_project_settings.R”. setup_lines: boilerplate bash code allow running R code HPC. Internally function sets sbatch task run git pull renv::restore() HPC. specific task need change sbatch options using hpc_configs$renv_sbatch_opts. asks 16GB RAM, 4 CPUs tell SLURM job take less 120 minutes. assigned result call wf (wf <- add_workflow_step(...)), function modified “workflows/networks_estimation/” folder. notes: MOX cluster HYAK, renv_sbatch_opts also changes partition “build” MOX “default” partition internet access.","code":"# Update RENV on the HPC ------------------------------------------------------- wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_renv_restore(     git_branch = current_git_branch,     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = hpc_configs$renv_sbatch_opts ) hpc_configs$renv_sbatch_opts #> list( #> \"mem\" = \"16G\", #> \"cpus-per-task\" = 4, #> \"time\" = 120 #> )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"addition-of-the-estimation-step","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Defining the “networks_estimation” workflow","what":"Addition of the estimation Step","title":"Using `slurmworkflow` with EpiModel","text":"Now ensured project date HPC, want run “R/01-networks_estimation.R” script context <- \"hpc\". add another step slurmworkflow::add_workflow_step different step template. slurmworkflow::step_tmpl_do_call_script template sets step run script located HPC path r_script, “R/01-networks_estimation.R”, variables pre-defined. set following variables: - context = \"hpc\": signals script use “hpc” settings. - estimation_method = \"MCMLE\": want slower accurate estimation method. - estimation_ncores = max_cores: estimation method benefits parallelized. (10 cores can slow things significantly). take look “R/01-networks_estimation.R” script, see estimation_method estimation_ncores set context == \"local\" “hpc”. Thanks step template defined script run part workflow. note: syntax step_tmpl_do_call_script pass arguments script similar one base::.call. Important note: users like clear R environment placing rm(list = ls()) start scripts. addition discouraged generally, actually prevent script work step_tmpl_do_call_script deletes variable start script. Restarting R session using callr package better alternatives working interactively. Finally, also provide setup_lines new sbatch_opts. “partition” option provided, default “epimodel” (using values set create_workflow beginning. step write 3 files HPC: (see script details) “data/intermediate/estimates/epistats-hpc.rds” “data/intermediate/estimates/netstats-hpc.rds” “data/intermediate/estimates/netest-hpc.rds”","code":"# Estimate the networks -------------------------------------------------------- wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_do_call_script(     r_script = \"./R/01-networks_estimation.R\",     args = list(       context = \"hpc\",       estimation_method = \"MCMLE\",       estimation_ncores = max_cores    ),     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = list(     \"cpus-per-task\" = max_cores,     \"time\" = \"24:00:00\",     \"mem\" = \"0\"   ) )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"addition-of-the-diagnostics-step","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Defining the “networks_estimation” workflow","what":"Addition of the diagnostics Step","title":"Using `slurmworkflow` with EpiModel","text":"Finally want generate diagnostics networks “R/02-networks_diagnostics.R”. step uses template , 3 variables passed script: context, ncores nsteps. last step workflow override “mail-type” sbatch option receive mail step ends. notified workflow finished. step write 3 files HPC: (see script details) “data/intermediate/calibration/netdx-main-hpc.rds” “data/intermediate/calibration/netdx-casl-hpc.rds” “data/intermediate/calibration/netdx-inst-hpc.rds”","code":"# Generate the diagnostics data ------------------------------------------------ wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_do_call_script(     r_script = \"./R/02-networks_diagnostics.R\",     args = list(       context = \"hpc\",       ncores = max_cores,       nsims = 50     ),     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = list(     \"cpus-per-task\" = max_cores,     \"time\" = \"04:00:00\",     \"mem-per-cpu\" = \"4G\",     \"mail-type\" = \"FAIL,END\"   ) )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"using-the-estimation-workflow-on-the-rsph-hpc","dir":"Articles","previous_headings":"Network Estimation and Diagnostics","what":"Using the “estimation” workflow on the RSPH HPC","title":"Using `slurmworkflow` with EpiModel","text":"Now estimation workflow set , need send HPC, run download results. assume “workflows/” “data/intermediate/” directories tracked git (using “.gitignore” example) user SSH access HPC. use scp copy folder HPC available Windows, MacOS GNU/Linux. example, “EpiModelHIV-Template” repository located “~/projects/EpiModelHIV-Template” HPC. sending workflow, make sure project HPC renv initialized. means running renv::init() root project HPC.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"sending-the-workflow-to-the-hpc","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Using the “estimation” workflow on the RSPH HPC","what":"Sending the workflow to the HPC","title":"Using `slurmworkflow` with EpiModel","text":"never used command line , recommend using terminal RStudio (R console). Everything written <angle brackets> replaced correct value. make sure understand part commands running . make life easier. following commands run local computer. MacOS GNU/Linux Windows Forgetting set DISPLAY= prevent scp working correctly. Note workflows\\networks_estimation. Windows uses back-slashes directories Unix OSes uses forward-slashes.","code":"# bash - local scp -r workflows/networks_estimation <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/workflows/ # bash - local set DISPLAY= scp -r workflows\\networks_estimation <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/workflows/"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"running-the-workflow-from-the-hpc","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Using the “estimation” workflow on the RSPH HPC","what":"Running the workflow from the HPC","title":"Using `slurmworkflow` with EpiModel","text":"step, must command line HPC. means run: ssh <user>@clogin01.sph.emory.edu local computer. run set DISPLAY= Windows get error: ssh_askpass: posix_spawnp: file directory also need root directory project (“.git” folder well “renv.lock” file”. example get running $ cd ~/projects/EpiModelHIV-Template. following steps work root project. Running workflow done executing file “workflows/estimation/start_workflow.sh” following command: using Windows, may executable. can solve following command: workflow work source file (source <script> . <script>).","code":"# bash - hpc ./workflows/estimation/start_workflow.sh # bash - hpc chmod +x workflows/estimation/start_workflow.sh`"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"downloading-the-results-for-analysis","dir":"Articles","previous_headings":"Network Estimation and Diagnostics > Using the “estimation” workflow on the RSPH HPC","what":"Downloading the Results for Analysis","title":"Using `slurmworkflow` with EpiModel","text":"Granting workflow worked correctly, receive mail telling last step ended exit code 0 (success, 0 errors). want download “data/intermediate/estimates/” “data/intermediate/diagnostics/” directories back local machine: command run local machine, SSH session HPC. MacOs GNU/Linux Windows notes Windows can now run R script “03-diagnostics_explore.R” see everything correct. Don’t forget set context “hpc” top file assess right networks.","code":"# bash - local scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/estimates data/intermediate/ scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/diagnostics data/intermediate/ # bash - local set DISPLAY= scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/estimates data\\intermediate\\ scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/diagnostics data\\intermediate\\"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"running-intervention-scenarios-of-the-model","dir":"Articles","previous_headings":"","what":"Running Intervention Scenarios of the Model","title":"Using `slurmworkflow` with EpiModel","text":"skip directly intervention scenarios workflow process similar calibration. point, assume “data/intermediate/estimates/restart-hpc.rds” file bunch scenarios defined “data/input/scenarios.csv” , differentiate command line MacOS, GNU/Linux Windows anymore.present UNIX version Windows user can apply rules previously required.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"overview-1","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model","what":"Overview","title":"Using `slurmworkflow` with EpiModel","text":"define 3 steps workflow: 1. renv_update step . 2. set nrep replications scenario. 3. processing step.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"defining-the-intervention_scenarios-workflow","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model","what":"Defining the “intervention_scenarios” workflow","title":"Using `slurmworkflow` with EpiModel","text":"script “R/workflow_05-intervention_scenario.R” responsible creation workflow.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"setup-creation-and-renvrestore","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model > Defining the “intervention_scenarios” workflow","what":"Setup, Creation and renv::restore","title":"Using `slurmworkflow` with EpiModel","text":"go quickly part similar previous workflow. tested numbered script locally, sourced files make sense .","code":"# Libraries -------------------------------------------------------------------- library(\"slurmworkflow\") library(\"EpiModelHPC\") library(\"EpiModelHIV\")  # Settings --------------------------------------------------------------------- source(\"./R/utils-0_project_settings.R\") context <- \"hpc\" max_cores <- 32  source(\"./R/utils-default_inputs.R\") # make `path_to_est`, `param` and `init` source(\"./R/utils-hpc_configs.R\") # creates `hpc_configs`  # ------------------------------------------------------------------------------  # Workflow creation wf <- create_workflow(   wf_name = \"intervention_scenarios\",   default_sbatch_opts = hpc_configs$default_sbatch_opts )  # Update RENV on the HPC wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_renv_restore(     git_branch = current_git_branch,     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = hpc_configs$renv_sbatch_opts )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"addition-of-the-simulation-step","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model > Defining the “intervention_scenarios” workflow","what":"Addition of the simulation Step","title":"Using `slurmworkflow` with EpiModel","text":"step assumes know run EpiModel network simulation. part similar local script “R/40-intervention_scenarios.R”. Terminology: - simulation: One run epidemic model. - scenario: set parameters simulation. See vignette(\"Working       Model Parameters\", package = \"EpiModel\") - batch: set ncores simulations run single cluster node. share scenario. step need path_to_restart, param, init control objects EpiModelHPC::netsim_scenarios call. loaded “R/utils-default_inputs.R”. control object differs ’s usual form nsims ncores argument overridden workflow. scripts, restart_time intervention_end loaded “R/utils-0_project_settings” script. Note simulations restart note time zero previous simulation. Therefore need specify different initialize.FUN handle restarting process. reinit_msm function EpiModelHIV-p. load tibble 2 scenarios found “data/input/scenarios.csv” transform scenario list. account variability models, want scenario run 120 times. (usually 500 1000 times final paper). use add_workflow_step create step. time use step template EpiModelHPC::step_tmpl_netsim_scenarios. takes arguments: path_to_est, param, init, control. path_to_est workflow look est file HPC. pass path_to_restart “data/intermediate/estimates/restart-hpc.rds” scenarios_list: list scenarios produced create_scenario_list output_dir: path directory store results libraries: character vector libraries required run model. need “EpiModelHIV” save_pattern: part sim object kept. Simple keep epi, param control. values can used use cases. n_rep: number time scenarios must simulated. (120) n_cores: number cores used node max_array_size detailed value 500 usually fine. setup_lines: . step run simulations save result output_dir using following format: paste0(\"sim__\", scenario[[\"id\"]], \"__\", batch_num, \".rds\"). running simulations 32 core machines, scenario run 4 batches, last one containing 24 simulations get desired 120. (3 * 32 + 24 == 120). NOTE: max_array_size argument allow us constrain many runs submitted . RSPH HPC one limited around 1000 job submission time. Trying submit result SLURM rejecting jobs. prevent , slurmworkflow split job parts submitted automatically one . length scenarios_list 3 000, max_array_size = 500 split 6 parts part submitted previous one .","code":"# Controls source(\"./R/utils-targets.R\") control <- control_msm(   start               = restart_time,   nsteps              = intervention_end,   nsims               = 1,   ncores              = 1,   initialize.FUN      = reinit_msm,   cumulative.edgelist = TRUE,   truncate.el.cuml    = 0,   .tracker.list       = calibration_trackers,   verbose             = FALSE ) scenarios_df <- readr::read_csv(\"./data/input/scenarios.csv\") scenarios_list <- EpiModel::create_scenario_list(scenarios_df) wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_netsim_scenarios(     path_to_restart, param, init, control,     scenarios_list = scenarios_list,     output_dir = \"./data/intermediate/scenarios\",     libraries = \"EpiModelHIV\",     save_pattern = \"simple\",     n_rep = 120,     n_cores = max_cores,     max_array_size = 500,     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = list(     \"mail-type\" = \"FAIL,TIME_LIMIT\",     \"cpus-per-task\" = max_cores,     \"time\" = \"04:00:00\",     \"mem\" = 0   ) )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"addition-of-the-processing-step","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model > Defining the “intervention_scenarios” workflow","what":"Addition of the processing Step","title":"Using `slurmworkflow` with EpiModel","text":"Now batches run process create small summary tibble downloaded evaluated locally. return step_tmpl_do_call_script steps. arguments pass script ncores, many cores use step process files parallel using future.apply package, context = \"hpc\" . script save two file: 1. “data/intermediate/scenarios/assessments_raws.rds” 2. “data/intermediate/scenarios/assessments.rds” See script see .","code":"# Process calibrations # # produce a data frame with the calibration targets for each scenario wf <- add_workflow_step(   wf_summary = wf,   step_tmpl = step_tmpl_do_call_script(     r_script = \"./R/41-intervention_scenarios_process.R\",     args = list(       context = \"hpc\",       ncores = 15     ),     setup_lines = hpc_configs$r_loader   ),   sbatch_opts = list(     \"cpus-per-task\" = max_cores,     \"time\" = \"04:00:00\",     \"mem-per-cpu\" = \"4G\",     \"mail-type\" = \"END\"   ) )"},{"path":"http://epimodel.github.io/EpiModelHPC/articles/epimodelhiv-slurmworkflow.html","id":"using-the-intervention_scenarios-workflow-on-the-rsph-hpc","dir":"Articles","previous_headings":"Running Intervention Scenarios of the Model","what":"Using the “intervention_scenarios” workflow on the RSPH HPC","title":"Using `slurmworkflow` with EpiModel","text":"send workflow : run project directory HPC : finally download results evaluation: can now use files please locally.","code":"# bash - local scp -r workflows/intervention_scenarios <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/workflows/ # bash - hpc ./workflows/intervention_scenarios/start_workflow.sh # bash - local scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/scenarios/assessments_raws.rds data/intermediate/calibration/ scp -r <user>@clogin01.sph.emory.edu:projects/EpiModelHIV-Template/data/intermediate/scenarios/assessments_raws.rds data/intermediate/scenarios/"},{"path":"http://epimodel.github.io/EpiModelHPC/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Samuel Jenness. Maintainer, author.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Jenness S (2025). EpiModelHPC: EpiModel Extensions High-Performance Computing. R package version 2.5.0, http://epimodel.org/.","code":"@Manual{,   title = {EpiModelHPC: EpiModel Extensions for High-Performance Computing},   author = {Samuel Jenness},   year = {2025},   note = {R package version 2.5.0},   url = {http://epimodel.org/}, }"},{"path":"http://epimodel.github.io/EpiModelHPC/index.html","id":"epimodelhpc","dir":"","previous_headings":"","what":"EpiModel Extensions for High-Performance Computing","title":"EpiModel Extensions for High-Performance Computing","text":"EpiModelHPC R package provides extensions simulating stochastic network models EpiModel high-performance computing (HPC) systems. Functionality provided simulate models parallel, checkpointing functions save restore simulation work. many potential HPCs systems, software developed standard within large-scale scientific computing: linux-based clusters operate job scheduling software running Slurm. types system necessary running EpiModelHPC: functionality package may useful system supports parallelization, including desktop computers multiple cores.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"EpiModel Extensions for High-Performance Computing","text":"software currently hosted Github . Install using remotes package:","code":"if (!require(\"remotes\")) install.packages(\"remotes\") remotes::install_github(\"EpiModel/EpiModelHPC\")"},{"path":[]},{"path":"http://epimodel.github.io/EpiModelHPC/reference/EpiModelHPC-package.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"EpiModel Extensions for High-Performance Computing — EpiModelHPC-package","text":"EpiModel provides tools mathematical modeling infectious diseases. Supported model classes include stochastic network models, rely statistical framework exponential-family random graph models (ERGMs) evolve time. allows modeling disease-related contacts duration, ongoing sexual partnerships. level statistical complexity models, based Markov-chain Monte Carlo (MCMC) simulation, results computationally intensive simulation processes. goal EpiModelHPC provide standardized framework extending EpiModel run modern high-performance computing (HPC) systems.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/EpiModelHPC-package.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"EpiModel Extensions for High-Performance Computing — EpiModelHPC-package","text":"main website EpiModel http://epimodel.org/. source code extension package hosted Github http://github.com/statnet/EpiModelHPC. Bug reports feature requests may filed .","code":""},{"path":[]},{"path":"http://epimodel.github.io/EpiModelHPC/reference/EpiModelHPC-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"EpiModel Extensions for High-Performance Computing — EpiModelHPC-package","text":"Maintainer: Samuel Jenness samuel.m.jenness@emory.edu","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/check_cp.html","id":null,"dir":"Reference","previous_headings":"","what":"Checks for Checkpointed Rdata Files — check_cp","title":"Checks for Checkpointed Rdata Files — check_cp","text":"Checks whether checkpointed data files specific format given simulation number.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/check_cp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checks for Checkpointed Rdata Files — check_cp","text":"","code":"check_cp(simno)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/check_cp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Checks for Checkpointed Rdata Files — check_cp","text":"simno Simulation number current model simulation, typically stored control$simno.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/check_cp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Checks for Checkpointed Rdata Files — check_cp","text":"function checks whether checkpointed data files available loading. Checkpointed data files incrementally saved simulation loaded simulation job cancelled restarted. done automatically within netsim_hpc function. Checkpointed data files searched specific subdirectory relative current working directory: data/sim<x>, <x> simno value. Within directory check_cp looks files ending .cp.rda, standard checkpoint data file name. Note standards file directory name consistent save_cpdata module function. running simulations using netsim_hpc function, data saving module automatically inserted workflow simulation. files tested see similar size, meaning file less 50% average file size others. Smaller size files usually indicates interim file saving interrupted. files exist correct size, full directory name returned, else NULL returned.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_batches_infos.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to access the file name elements of scenarios — get_scenarios_batches_infos","title":"Helper function to access the file name elements of scenarios — get_scenarios_batches_infos","text":"function returns list simulation files corresponding scenario name batch number present given directory. meant used netsim_scenarios step_tmpl_netsim_scenarios.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_batches_infos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to access the file name elements of scenarios — get_scenarios_batches_infos","text":"","code":"get_scenarios_batches_infos(scenario_dir)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_batches_infos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to access the file name elements of scenarios — get_scenarios_batches_infos","text":"scenario_dir directory netsim_scenarios saved simulations.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_batches_infos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to access the file name elements of scenarios — get_scenarios_batches_infos","text":"tibble three columns: file_path - full paths simulation file, scenario_name associated scenario name, batch_number associated batch number.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_tibble_infos.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to access the infos on merged scenarios data.frame — get_scenarios_tibble_infos","title":"Helper function to access the infos on merged scenarios data.frame — get_scenarios_tibble_infos","text":"function returns list scenario tibble files corresponding scenario name present given directory. meant used merge_netsim_scenarios_tibble step_tmpl_merge_netsim_scenarios_tibble.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_tibble_infos.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to access the infos on merged scenarios data.frame — get_scenarios_tibble_infos","text":"","code":"get_scenarios_tibble_infos(scenario_dir)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_tibble_infos.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to access the infos on merged scenarios data.frame — get_scenarios_tibble_infos","text":"scenario_dir directory merge_netsim_scenarios_tibble saved merged tibbles.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/get_scenarios_tibble_infos.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to access the infos on merged scenarios data.frame — get_scenarios_tibble_infos","text":"tibble two columns: file_path - full path scenario tibble file scenario_name associated scenario name.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/initialize_cp.html","id":null,"dir":"Reference","previous_headings":"","what":"Initializes Network Model after Checkpointing — initialize_cp","title":"Initializes Network Model after Checkpointing — initialize_cp","text":"Sets parameters, initial conditions, control settings data object, necessary checkpointing simulations.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/initialize_cp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Initializes Network Model after Checkpointing — initialize_cp","text":"","code":"initialize_cp(x, param, init, control, s)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/initialize_cp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Initializes Network Model after Checkpointing — initialize_cp","text":"x EpiModel object class netest. param EpiModel object class param.net. init EpiModel object class init.net. control EpiModel object class control.net. s Simulation number, used restarting dependent simulations.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/initialize_cp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Initializes Network Model after Checkpointing — initialize_cp","text":"running stochastic network model checkpointed data, necessary run originally specified initialization module. Instead, initialization module reset parameters, initial conditions, control settings back onto data object. module intended used context running simulations high-performance computing settings using netsim_hpc. function automatically replaces original initialization function checkpointed version simulation checkpoint state.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/make_calibrated_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Make an EpiModel scenario using the result of an swfcalib calibration — make_calibrated_scenario","title":"Make an EpiModel scenario using the result of an swfcalib calibration — make_calibrated_scenario","text":"Make EpiModel scenario using result swfcalib calibration","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/make_calibrated_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make an EpiModel scenario using the result of an swfcalib calibration — make_calibrated_scenario","text":"","code":"make_calibrated_scenario(calib_object)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/make_calibrated_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make an EpiModel scenario using the result of an swfcalib calibration — make_calibrated_scenario","text":"calib_object formatted calibration object","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios","text":"Create Single Sim File per Scenarios Using Files netsim_scenarios","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios","text":"","code":"merge_netsim_scenarios(   sim_dir,   output_dir,   keep.transmat = TRUE,   keep.network = TRUE,   keep.nwstats = TRUE,   keep.other = TRUE,   param.error = FALSE,   keep.diss.stats = TRUE,   truncate.at = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios","text":"sim_dir folder simulation files stored. output_dir folder merged files stored. keep.transmat TRUE, keep transmission matrices original x y elements. Note: transmission matrices saved (save.transmat == TRUE). keep.network TRUE, keep networkDynamic objects original x y elements. Note: network saved (tergmLite == FALSE). keep.nwstats TRUE, keep network statistics (set nwstats.formula parameter control.netsim) original x y elements. keep.TRUE, keep simulation elements (set save.parameter control.netsim) original x y elements. param.error TRUE, x y different params (param.net) controls (passed control.net) error prevent merge. Use FALSE override check. keep.diss.stats TRUE, keep diss.stats original x y objects. truncate.Time step left-truncate time series.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios_tibble","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios_tibble","text":"Create Single Sim File per Scenarios Using Files netsim_scenarios","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios_tibble","text":"","code":"merge_netsim_scenarios_tibble(   sim_dir,   output_dir,   steps_to_keep,   cols = dplyr::everything() )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_netsim_scenarios_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — merge_netsim_scenarios_tibble","text":"sim_dir folder simulation files stored. output_dir folder merged files stored. steps_to_keep Numbers time steps add end simulation keep data.frame. cols columns keep data.frame. default columns kept. case, batch_number, sim time always kept.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_simfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Simulation Data from Stochastic Network Models — merge_simfiles","title":"Save Simulation Data from Stochastic Network Models — merge_simfiles","text":"Saves Rdata file containing stochastic network model output netsim function calls time-stamped file names.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_simfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Simulation Data from Stochastic Network Models — merge_simfiles","text":"","code":"merge_simfiles(   simno,   ftype = \"min\",   indir = \"data/\",   vars = NULL,   truncate.at = NULL,   keep.other = FALSE,   verbose = TRUE )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_simfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Simulation Data from Stochastic Network Models — merge_simfiles","text":"simno First components simulation number standard format written savesim (see details). ftype Type file merged, either \"min\" compacted files \"max\" large files. File availability depends files saved savesim. indir File directory relative working directory simulation files stored. vars Character vector variables stored epi sub-list retain output data. variables specified, network statistics ancillary data removed. truncate.Left-truncates simulation epidemiological summary statistics network statistics specified time step. keep.TRUE, keep simulation elements (set save.parameter control.netsim) original x y elements. verbose TRUE, print file load progress console.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/merge_simfiles.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save Simulation Data from Stochastic Network Models — merge_simfiles","text":"function merges individual simulation runs stored separate Rdata files one larger output object analysis. function typically used running netsim_hpc array job specification (see vignette) order combine individual blocks simulations one complete set. simno argument must therefore specified first component simulation number: passed -v parameter qsub. example, one like aggregate two files simulation number 1 stored sim.n1.1.* sim.n1.2.* files, simno argument 1.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_hpc.html","id":null,"dir":"Reference","previous_headings":"","what":"Stochastic Network Models on High-Performance Computing Systems — netsim_hpc","title":"Stochastic Network Models on High-Performance Computing Systems — netsim_hpc","text":"Simulates stochastic network epidemic models infectious disease dynamics parallel.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_hpc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stochastic Network Models on High-Performance Computing Systems — netsim_hpc","text":"","code":"netsim_hpc(   x,   param,   init,   control,   cp.save.int = NULL,   save.min = TRUE,   save.max = FALSE,   compress = TRUE,   verbose = TRUE )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_hpc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stochastic Network Models on High-Performance Computing Systems — netsim_hpc","text":"x Character vector containing file path Rdata file object class netest stored. Alternatively, restarting previous simulation, may file path object class netsim. param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. cp.save.int Check-pointing save interval, used specify often intermediate data saved disk. job check-pointed, resume automatically last saved time step stored disk. set NULL, intermediate data storage occur. save.min Argument passed savesim. save.max Argument passed savesim. compress Matches compress argument save function. verbose FALSE, suppress output messages except errors.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_hpc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Stochastic Network Models on High-Performance Computing Systems — netsim_hpc","text":"function provides systematic method running stochastic network models parallel high-performance computing systems. main purpose using netsim_hpc standardized checkpointing method. Checkpointing defined incrementally saving simulation data purpose reloading simulation job canceled restarted. checkpointing needed, users advised run models directly EpiModel::netsim function. function performs following tasks: Check existence checkpointed data, using check_cp function. CP data available, checkpointed model run, else new model run. Create checkpoint directory one exist \"data/simsimno\". related checkpointing functions occur cp.save.int set NULL. Sets checkpoint save interval number time steps specified cp.save.int. Resets initialize module function initialize_cp checkpoint state. Run simulation, either new checkpointed, call EpiModel::netsim. Save completed simulation data, using functionality savesim. Remove checkpointed data file directory created step 1, exists. x argument must specify file name character string, rather netest netsim class object directly. mainly efficiency purposes running models parallel. save.min save.max set FALSE, function return rather save output EpiModel object.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_one_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Run one netsim call with a scenario and saves the results deterministically — netsim_run_one_scenario","title":"Run one netsim call with a scenario and saves the results deterministically — netsim_run_one_scenario","text":"inner function called netsim_scenarios step_tmpl_netsim_scenarios.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_one_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run one netsim call with a scenario and saves the results deterministically — netsim_run_one_scenario","text":"","code":"netsim_run_one_scenario(   scenario,   batch_num,   path_to_x,   param,   init,   control,   libraries,   output_dir,   n_batch,   n_rep,   n_cores )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_one_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run one netsim call with a scenario and saves the results deterministically — netsim_run_one_scenario","text":"scenario single \"EpiModel scenario\" used simulation batch_num batch number, calculated number replications CPUs required. path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID) output_dir folder simulation files stored. n_batch number batches run ceiling(n_rep / n_cores). n_rep number replication run scenario. n_cores number CPUs simulations run.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_one_scenario.html","id":"checkpointing","dir":"Reference","previous_headings":"","what":"Checkpointing","title":"Run one netsim call with a scenario and saves the results deterministically — netsim_run_one_scenario","text":"function takes care editing .checkpoint.dir create unique sub directories scenario. EpiModel::control.net way setting checkpoints can used transparently.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_swfcalib_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Run one netsim call with the result of an swfcalib calibration — netsim_run_swfcalib_scenario","title":"Run one netsim call with the result of an swfcalib calibration — netsim_run_swfcalib_scenario","text":"Run one netsim call result swfcalib calibration","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_swfcalib_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Run one netsim call with the result of an swfcalib calibration — netsim_run_swfcalib_scenario","text":"","code":"netsim_run_swfcalib_scenario(   calib_object,   batch_num,   path_to_x,   param,   init,   control,   libraries,   output_dir,   n_batch,   n_rep,   n_cores )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_run_swfcalib_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Run one netsim call with the result of an swfcalib calibration — netsim_run_swfcalib_scenario","text":"calib_object formatted calibration object batch_num batch number, calculated number replications CPUs required. path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID) output_dir folder simulation files stored. n_batch number batches run ceiling(n_rep / n_cores). n_rep number replication run scenario. n_cores number cores run processing ","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to run EpiModel network simulations with scenarios — netsim_scenarios","title":"Function to run EpiModel network simulations with scenarios — netsim_scenarios","text":"function run n_rep replications scenarios scenarios_list. runs multiple batches n_cores simulations time. simfiles stored output_dir folder named using following pattern: \"sim__name_of_scenario__2.rds\". last number batch number particular scenario. scenario therefore run ceiling(n_rep / n_cores) batches. function meant mimic behavior step_tmpl_netsim_scenarios local machine. fail similar fashion reciprocally, runs correctly locally, moving HPC produce issue.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to run EpiModel network simulations with scenarios — netsim_scenarios","text":"","code":"netsim_scenarios(   path_to_x,   param,   init,   control,   scenarios_list,   n_rep,   n_cores,   output_dir,   libraries = NULL,   ... )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to run EpiModel network simulations with scenarios — netsim_scenarios","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. scenarios_list list scenarios run. Produced EpiModel::create_scenario_list function n_rep number replication run scenario. n_cores number CPUs simulations run. output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID) ... compatibility reasons","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios.html","id":"checkpointing","dir":"Reference","previous_headings":"","what":"Checkpointing","title":"Function to run EpiModel network simulations with scenarios — netsim_scenarios","text":"function takes care editing .checkpoint.dir create unique sub directories scenario. EpiModel::control.net way setting checkpoints can used transparently.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create the parameters for netsim_run_one_scenario — netsim_scenarios_setup","title":"Helper function to create the parameters for netsim_run_one_scenario — netsim_scenarios_setup","text":"Helper function  create parameters netsim_run_one_scenario","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create the parameters for netsim_run_one_scenario — netsim_scenarios_setup","text":"","code":"netsim_scenarios_setup(   path_to_x,   param,   init,   control,   scenarios_list,   n_rep,   n_cores,   output_dir,   libraries )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create the parameters for netsim_run_one_scenario — netsim_scenarios_setup","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. scenarios_list list scenarios run. Produced EpiModel::create_scenario_list function n_rep number replication run scenario. n_cores number CPUs simulations run. output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_scenarios_setup.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Helper function to create the parameters for netsim_run_one_scenario — netsim_scenarios_setup","text":"list arguments netsim_run_one_scenario","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"Function run EpiModel sim result swfcalib calibration","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"","code":"netsim_swfcalib_output(   path_to_x,   param,   init,   control,   calib_object,   n_rep,   n_cores,   output_dir,   libraries = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. calib_object formatted calibration object n_rep number replication run scenario. n_cores number CPUs simulations run. output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":"checkpointing","dir":"Reference","previous_headings":"","what":"Checkpointing","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"function takes care editing .checkpoint.dir create unique sub directories scenario. EpiModel::control.net way setting checkpoints can used transparently.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output.html","id":"step-template","dir":"Reference","previous_headings":"","what":"Step Template","title":"Function to run an EpiModel sim with the result of an swfcalib calibration — netsim_swfcalib_output","text":"Step Templates helper functions used within add_workflow_step. basic ones provided slurmworkflow package. instruct workflow run either bash script, set bash lines given character vector R script. Additional Step Templates can created simplify specific tasks. easiest way wrappers around existing templates.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output_setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Helper function to create the parameters for netsim_run_swfcalib_scenario — netsim_swfcalib_output_setup","title":"Helper function to create the parameters for netsim_run_swfcalib_scenario — netsim_swfcalib_output_setup","text":"Helper function  create parameters netsim_run_swfcalib_scenario","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output_setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Helper function to create the parameters for netsim_run_swfcalib_scenario — netsim_swfcalib_output_setup","text":"","code":"netsim_swfcalib_output_setup(   path_to_x,   param,   init,   control,   calib_object,   n_rep,   n_cores,   output_dir,   libraries )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/netsim_swfcalib_output_setup.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Helper function to create the parameters for netsim_run_swfcalib_scenario — netsim_swfcalib_output_setup","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. calib_object formatted calibration object n_rep number replication run scenario. n_cores number cores run processing output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/process_simfiles.html","id":null,"dir":"Reference","previous_headings":"","what":"Process sub-job simulation files saved as a series of Rdata files. — process_simfiles","title":"Process sub-job simulation files saved as a series of Rdata files. — process_simfiles","text":"Wraps merge_simfiles function merge sub-job Rdata files saves single output file, option delete sub-job files.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/process_simfiles.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Process sub-job simulation files saved as a series of Rdata files. — process_simfiles","text":"","code":"process_simfiles(   simno = NA,   indir = \"data/\",   outdir = \"data/\",   vars = NULL,   truncate.at = NULL,   min.n,   nsims,   compress = \"xz\",   delete.sub = TRUE,   verbose = FALSE )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/process_simfiles.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Process sub-job simulation files saved as a series of Rdata files. — process_simfiles","text":"simno Simulation number process. indir File directory relative working directory simulation files stored. outdir File directory relative working directory simulation files saved. vars Argument passed merge_simfiles. truncate.Left-truncates simulation epidemiological summary statistics network statistics specified time step. min.n Integer value minimum number simulation files eligible processing. nsims Total number simulations across sub-jobs. compress Argument passed save. delete.sub Delete sub-job files merge saving. verbose Logical, print progress console.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/pull_env_vars.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull Standard Environmental Variables in Slurm Jobs — pull_env_vars","title":"Pull Standard Environmental Variables in Slurm Jobs — pull_env_vars","text":"Pulls four environmental variables commonly used Slurm jobs directly Global Environment R Script.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/pull_env_vars.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull Standard Environmental Variables in Slurm Jobs — pull_env_vars","text":"","code":"pull_env_vars(standard.vars = TRUE, num.vars, char.vars, logic.vars)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/pull_env_vars.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull Standard Environmental Variables in Slurm Jobs — pull_env_vars","text":"standard.vars Pull assign four standard Slurm variables: simno, jobno, ncores, njobs. num.vars Vector environmental variables pull assign numeric global environment. char.vars Vector environmental variables pull assign character global environment. logic.vars Vector environmental variables pull assign logical global environment.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/pull_env_vars.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pull Standard Environmental Variables in Slurm Jobs — pull_env_vars","text":"","code":"Sys.setenv(\"SIMNO\"=23) Sys.setenv(\"SLURM_ARRAY_TASK_ID\"=4) Sys.setenv(\"SLURM_CPUS_PER_TASK\"=4) Sys.setenv(\"NJOBS\"=10) Sys.setenv(\"NSIMS\"=100)  pull_env_vars(standard.vars = TRUE) ls() #> character(0)  Sys.setenv(\"tprob\"=0.1) Sys.setenv(\"rrate\"=14) Sys.setenv(\"scenario\"=\"base\") Sys.setenv(\"condition\"=TRUE)  pull_env_vars(num.vars = c(\"tprob\", \"rrate\"),               char.vars = \"scenario\",               logic.vars = \"condition\") ls() #> character(0)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/save_cpdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves for Network Simulation Rdata Files for Checkpointing — save_cpdata","title":"Saves for Network Simulation Rdata Files for Checkpointing — save_cpdata","text":"Module save simulation data stochastic network models disk specified time intervals.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/save_cpdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves for Network Simulation Rdata Files for Checkpointing — save_cpdata","text":"","code":"save_cpdata(dat, at)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/save_cpdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Saves for Network Simulation Rdata Files for Checkpointing — save_cpdata","text":"dat master data object used models simulated netsim. Current time step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/save_cpdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Saves for Network Simulation Rdata Files for Checkpointing — save_cpdata","text":"module saves data standardized location standardized file names purposes checkpointing. intended used running simulations netsim_hpc, automatically inserted workflow done.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/savesim.html","id":null,"dir":"Reference","previous_headings":"","what":"Save Simulation Data from Stochastic Network Models — savesim","title":"Save Simulation Data from Stochastic Network Models — savesim","text":"Saves Rdata file containing stochastic network model output netsim function calls time-stamped file names.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/savesim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Save Simulation Data from Stochastic Network Models — savesim","text":"","code":"savesim(   sim,   data.dir = \"data/\",   save.min = TRUE,   save.max = TRUE,   time.stamp = TRUE,   compress = FALSE )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/savesim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Save Simulation Data from Stochastic Network Models — savesim","text":"sim EpiModel object class netsim saved Rdata file. data.dir Path save data files. Directory created already exist. save.min TRUE, saves small version netsim object large elements data structure like network object transmission data frame removed. resulting name small file \".min\" appended end. save.max TRUE, saves full netsim object without deletions. time.stamp TRUE, saves file time stamp file name. compress Matches compress argument save function.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/savesim.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Save Simulation Data from Stochastic Network Models — savesim","text":"function provides automated method saving time-stamped Rdata file containing simulation number stochastic network model run netsim.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/sbatch_master.html","id":null,"dir":"Reference","previous_headings":"","what":"Create sbatch Bash Shell Script with Parameter Combination — sbatch_master","title":"Create sbatch Bash Shell Script with Parameter Combination — sbatch_master","text":"Creates master-level SLURM::sbatch script given set parameter combinations implied environmental arguments used parameters.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/sbatch_master.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create sbatch Bash Shell Script with Parameter Combination — sbatch_master","text":"","code":"sbatch_master(   vars,   expand.vars = TRUE,   working.dir = \"\",   master.file = \"\",   runsim.file = \"runsim.sh\",   build.runsim = FALSE,   env.file = \"~/loadR.sh\",   rscript.file = \"sim.R\",   param.file = NULL,   param.tag = NULL,   simno.start,   nsims = 100,   ncores = 16,   narray = NULL,   ckpt = FALSE,   append = FALSE,   mem = \"55G\",   walltime = \"1:00:00\",   jobname,   partition.main = \"csde\",   partition.ckpt = \"ckpt\",   account.main = \"csde\",   account.ckpt = \"csde-ckpt\" )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/sbatch_master.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create sbatch Bash Shell Script with Parameter Combination — sbatch_master","text":"vars list parameters varying values (see examples ). expand.vars TRUE, expand grid individual vars, else individual vars must vectors equal length. working.dir Path write master.file, specified runsim.file param.file. master.file Name output bash shell script file write. \"\", print console. runsim.file Name bash shell script file contains R batch commands executed sbatch. build.runsim TRUE, write bash shell script file name runsim.file loads R environment listed env.file execute Rscript file listed rscript.file. env.file Bash shell script load R environment desired. Optionally kept user's home directory default file name. Example script . rscript.file Name .R file contains primary simulation executed Rscript. param.file Name csv file write list varying parameters simulation numbers set within function. param.tag Character string current scenario batch added param.sheet. simno.start Starting number SIMNO variable. missing append=TRUE, read lines outfile start numbering one previous maximum. nsims Total number simulations across array jobs. ncores Number cores per node use within Slurm job. narray Number array batches within Slurm job. NULL, use nsims/ncores array batches. ckpt TRUE, use checkpoint queue submit jobs. numeric, specify first X jobs grid non-backfill. append TRUE, append lines previously created shell script. New simno either start value simno.start previous value missing. mem Amount memory needed per node within Slurm job. walltime Amount clock time needed per Slurm job. jobname Job name assigned Slurm job. unspecified, defaults simulation number job. partition.main Name primary HPC partition (passed -p). partition.ckpt Name checkpoint HPC partition (passed -p). account.main Name primary account (passed -). account.ckpt Name checkpoint account (passed -).","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/sbatch_master.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create sbatch Bash Shell Script with Parameter Combination — sbatch_master","text":"","code":"# Examples printing to console vars <- list(A = 1:5, B = seq(0.5, 1.5, 0.5)) sbatch_master(vars) #> #!/bin/bash #>  #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1 --export=ALL,SIMNO=1,NJOBS=7,NSIMS=100,A=1,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s2 --export=ALL,SIMNO=2,NJOBS=7,NSIMS=100,A=2,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s3 --export=ALL,SIMNO=3,NJOBS=7,NSIMS=100,A=3,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s4 --export=ALL,SIMNO=4,NJOBS=7,NSIMS=100,A=4,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s5 --export=ALL,SIMNO=5,NJOBS=7,NSIMS=100,A=5,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s6 --export=ALL,SIMNO=6,NJOBS=7,NSIMS=100,A=1,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s7 --export=ALL,SIMNO=7,NJOBS=7,NSIMS=100,A=2,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s8 --export=ALL,SIMNO=8,NJOBS=7,NSIMS=100,A=3,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s9 --export=ALL,SIMNO=9,NJOBS=7,NSIMS=100,A=4,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s10 --export=ALL,SIMNO=10,NJOBS=7,NSIMS=100,A=5,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s11 --export=ALL,SIMNO=11,NJOBS=7,NSIMS=100,A=1,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s12 --export=ALL,SIMNO=12,NJOBS=7,NSIMS=100,A=2,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s13 --export=ALL,SIMNO=13,NJOBS=7,NSIMS=100,A=3,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s14 --export=ALL,SIMNO=14,NJOBS=7,NSIMS=100,A=4,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s15 --export=ALL,SIMNO=15,NJOBS=7,NSIMS=100,A=5,B=1.5 runsim.sh sbatch_master(vars, nsims = 250) #> #!/bin/bash #>  #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1 --export=ALL,SIMNO=1,NJOBS=16,NSIMS=250,A=1,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s2 --export=ALL,SIMNO=2,NJOBS=16,NSIMS=250,A=2,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s3 --export=ALL,SIMNO=3,NJOBS=16,NSIMS=250,A=3,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s4 --export=ALL,SIMNO=4,NJOBS=16,NSIMS=250,A=4,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s5 --export=ALL,SIMNO=5,NJOBS=16,NSIMS=250,A=5,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s6 --export=ALL,SIMNO=6,NJOBS=16,NSIMS=250,A=1,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s7 --export=ALL,SIMNO=7,NJOBS=16,NSIMS=250,A=2,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s8 --export=ALL,SIMNO=8,NJOBS=16,NSIMS=250,A=3,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s9 --export=ALL,SIMNO=9,NJOBS=16,NSIMS=250,A=4,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s10 --export=ALL,SIMNO=10,NJOBS=16,NSIMS=250,A=5,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s11 --export=ALL,SIMNO=11,NJOBS=16,NSIMS=250,A=1,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s12 --export=ALL,SIMNO=12,NJOBS=16,NSIMS=250,A=2,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s13 --export=ALL,SIMNO=13,NJOBS=16,NSIMS=250,A=3,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s14 --export=ALL,SIMNO=14,NJOBS=16,NSIMS=250,A=4,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-16 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s15 --export=ALL,SIMNO=15,NJOBS=16,NSIMS=250,A=5,B=1.5 runsim.sh sbatch_master(vars, ckpt = TRUE) #> #!/bin/bash #>  #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1 --export=ALL,SIMNO=1,NJOBS=7,NSIMS=100,A=1,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s2 --export=ALL,SIMNO=2,NJOBS=7,NSIMS=100,A=2,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s3 --export=ALL,SIMNO=3,NJOBS=7,NSIMS=100,A=3,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s4 --export=ALL,SIMNO=4,NJOBS=7,NSIMS=100,A=4,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s5 --export=ALL,SIMNO=5,NJOBS=7,NSIMS=100,A=5,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s6 --export=ALL,SIMNO=6,NJOBS=7,NSIMS=100,A=1,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s7 --export=ALL,SIMNO=7,NJOBS=7,NSIMS=100,A=2,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s8 --export=ALL,SIMNO=8,NJOBS=7,NSIMS=100,A=3,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s9 --export=ALL,SIMNO=9,NJOBS=7,NSIMS=100,A=4,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s10 --export=ALL,SIMNO=10,NJOBS=7,NSIMS=100,A=5,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s11 --export=ALL,SIMNO=11,NJOBS=7,NSIMS=100,A=1,B=1.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s12 --export=ALL,SIMNO=12,NJOBS=7,NSIMS=100,A=2,B=1.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s13 --export=ALL,SIMNO=13,NJOBS=7,NSIMS=100,A=3,B=1.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s14 --export=ALL,SIMNO=14,NJOBS=7,NSIMS=100,A=4,B=1.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s15 --export=ALL,SIMNO=15,NJOBS=7,NSIMS=100,A=5,B=1.5 runsim.sh sbatch_master(vars, nsims = 50, ckpt = 10) #> #!/bin/bash #>  #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1 --export=ALL,SIMNO=1,NJOBS=4,NSIMS=50,A=1,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s2 --export=ALL,SIMNO=2,NJOBS=4,NSIMS=50,A=2,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s3 --export=ALL,SIMNO=3,NJOBS=4,NSIMS=50,A=3,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s4 --export=ALL,SIMNO=4,NJOBS=4,NSIMS=50,A=4,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s5 --export=ALL,SIMNO=5,NJOBS=4,NSIMS=50,A=5,B=0.5 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s6 --export=ALL,SIMNO=6,NJOBS=4,NSIMS=50,A=1,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s7 --export=ALL,SIMNO=7,NJOBS=4,NSIMS=50,A=2,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s8 --export=ALL,SIMNO=8,NJOBS=4,NSIMS=50,A=3,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s9 --export=ALL,SIMNO=9,NJOBS=4,NSIMS=50,A=4,B=1 runsim.sh #> sbatch -p ckpt -A csde-ckpt --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s10 --export=ALL,SIMNO=10,NJOBS=4,NSIMS=50,A=5,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s11 --export=ALL,SIMNO=11,NJOBS=4,NSIMS=50,A=1,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s12 --export=ALL,SIMNO=12,NJOBS=4,NSIMS=50,A=2,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s13 --export=ALL,SIMNO=13,NJOBS=4,NSIMS=50,A=3,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s14 --export=ALL,SIMNO=14,NJOBS=4,NSIMS=50,A=4,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-4 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s15 --export=ALL,SIMNO=15,NJOBS=4,NSIMS=50,A=5,B=1.5 runsim.sh sbatch_master(vars, simno.start = 1000) #> #!/bin/bash #>  #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1000 --export=ALL,SIMNO=1000,NJOBS=7,NSIMS=100,A=1,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1001 --export=ALL,SIMNO=1001,NJOBS=7,NSIMS=100,A=2,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1002 --export=ALL,SIMNO=1002,NJOBS=7,NSIMS=100,A=3,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1003 --export=ALL,SIMNO=1003,NJOBS=7,NSIMS=100,A=4,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1004 --export=ALL,SIMNO=1004,NJOBS=7,NSIMS=100,A=5,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1005 --export=ALL,SIMNO=1005,NJOBS=7,NSIMS=100,A=1,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1006 --export=ALL,SIMNO=1006,NJOBS=7,NSIMS=100,A=2,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1007 --export=ALL,SIMNO=1007,NJOBS=7,NSIMS=100,A=3,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1008 --export=ALL,SIMNO=1008,NJOBS=7,NSIMS=100,A=4,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1009 --export=ALL,SIMNO=1009,NJOBS=7,NSIMS=100,A=5,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1010 --export=ALL,SIMNO=1010,NJOBS=7,NSIMS=100,A=1,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1011 --export=ALL,SIMNO=1011,NJOBS=7,NSIMS=100,A=2,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1012 --export=ALL,SIMNO=1012,NJOBS=7,NSIMS=100,A=3,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1013 --export=ALL,SIMNO=1013,NJOBS=7,NSIMS=100,A=4,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=s1014 --export=ALL,SIMNO=1014,NJOBS=7,NSIMS=100,A=5,B=1.5 runsim.sh sbatch_master(vars, jobname = \"epiSim\") #> #!/bin/bash #>  #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=1,NJOBS=7,NSIMS=100,A=1,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=2,NJOBS=7,NSIMS=100,A=2,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=3,NJOBS=7,NSIMS=100,A=3,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=4,NJOBS=7,NSIMS=100,A=4,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=5,NJOBS=7,NSIMS=100,A=5,B=0.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=6,NJOBS=7,NSIMS=100,A=1,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=7,NJOBS=7,NSIMS=100,A=2,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=8,NJOBS=7,NSIMS=100,A=3,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=9,NJOBS=7,NSIMS=100,A=4,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=10,NJOBS=7,NSIMS=100,A=5,B=1 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=11,NJOBS=7,NSIMS=100,A=1,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=12,NJOBS=7,NSIMS=100,A=2,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=13,NJOBS=7,NSIMS=100,A=3,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=14,NJOBS=7,NSIMS=100,A=4,B=1.5 runsim.sh #> sbatch -p csde -A csde --array=1-7 --nodes=1 --cpus-per-task=16 --time=1:00:00 --mem=55G --job-name=epiSim --export=ALL,SIMNO=15,NJOBS=7,NSIMS=100,A=5,B=1.5 runsim.sh  if (FALSE) { # \\dontrun{ # Full-scale example writing out files sbatch_master(vars, nsims = 50, simno.start = 1000, build.runsim = TRUE,               master.file = \"master.sh\", param.sheet = \"params.csv\") sbatch_master(vars, nsims = 50, append = TRUE,               master.file = \"master.sh\", param.sheet = \"params.csv\")  } # }"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","text":"Step Template Create Single Sim File per Scenarios Using Files netsim_scenarios","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","text":"","code":"step_tmpl_merge_netsim_scenarios(   sim_dir,   output_dir,   keep.transmat = TRUE,   keep.network = TRUE,   keep.nwstats = TRUE,   keep.other = TRUE,   param.error = FALSE,   keep.diss.stats = TRUE,   truncate.at = NULL,   n_cores = 1,   setup_lines = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","text":"sim_dir folder simulation files stored. output_dir folder merged files stored. keep.transmat TRUE, keep transmission matrices original x y elements. Note: transmission matrices saved (save.transmat == TRUE). keep.network TRUE, keep networkDynamic objects original x y elements. Note: network saved (tergmLite == FALSE). keep.nwstats TRUE, keep network statistics (set nwstats.formula parameter control.netsim) original x y elements. keep.TRUE, keep simulation elements (set save.parameter control.netsim) original x y elements. param.error TRUE, x y different params (param.net) controls (passed control.net) error prevent merge. Use FALSE override check. keep.diss.stats TRUE, keep diss.stats original x y objects. truncate.Time step left-truncate time series. n_cores Parallelize process n_cores (default = 1) setup_lines (optional) vector bash lines run first. can used load required modules (like R, python, etc).","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios.html","id":"step-template","dir":"Reference","previous_headings":"","what":"Step Template","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios","text":"Step Templates helper functions used within add_workflow_step. basic ones provided slurmworkflow package. instruct workflow run either bash script, set bash lines given character vector R script. Additional Step Templates can created simplify specific tasks. easiest way wrappers around existing templates.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios_tibble.html","id":null,"dir":"Reference","previous_headings":"","what":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","text":"Step Template Create Single Sim File per Scenarios Using Files netsim_scenarios","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios_tibble.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","text":"","code":"step_tmpl_merge_netsim_scenarios_tibble(   sim_dir,   output_dir,   steps_to_keep,   cols = dplyr::everything(),   n_cores = 1,   setup_lines = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios_tibble.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","text":"sim_dir folder simulation files stored. output_dir folder merged files stored. steps_to_keep Numbers time steps add end simulation keep data.frame. cols columns keep data.frame. default columns kept. case, batch_number, sim time always kept. n_cores Parallelize process n_cores (default = 1) setup_lines (optional) vector bash lines run first. can used load required modules (like R, python, etc).","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios_tibble.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_merge_netsim_scenarios_tibble.html","id":"step-template","dir":"Reference","previous_headings":"","what":"Step Template","title":"Step Template to Create a Single Sim File per Scenarios Using the Files From netsim_scenarios — step_tmpl_merge_netsim_scenarios_tibble","text":"Step Templates helper functions used within add_workflow_step. basic ones provided slurmworkflow package. instruct workflow run either bash script, set bash lines given character vector R script. Additional Step Templates can created simplify specific tasks. easiest way wrappers around existing templates.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":null,"dir":"Reference","previous_headings":"","what":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"step template similar netsim_scenarios HPC. uses slurmworkflow::step_tmpl_map internally used slurmworkflow step. details, see netsim_scenarios documentation.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"","code":"step_tmpl_netsim_scenarios(   path_to_x,   param,   init,   control,   scenarios_list,   n_rep,   n_cores,   output_dir,   libraries = NULL,   setup_lines = NULL,   max_array_size = NULL,   ... )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. scenarios_list list scenarios run. Produced EpiModel::create_scenario_list function n_rep number replication run scenario. n_cores number CPUs simulations run. output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID) setup_lines (optional) vector bash lines run first. can used load required modules (like R, python, etc). max_array_size maximum number array jobs submitted time. strictly less maximum number jobs allowed submit slurm HPC. ... arguments vectorize (vectors lists strictly positive length, zero length).  See also ‘Details’.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":"checkpointing","dir":"Reference","previous_headings":"","what":"Checkpointing","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"function takes care editing .checkpoint.dir create unique sub directories scenario. EpiModel::control.net way setting checkpoints can used transparently.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_scenarios.html","id":"step-template","dir":"Reference","previous_headings":"","what":"Step Template","title":"Step template to run EpiModel network simulations with scenarios — step_tmpl_netsim_scenarios","text":"Step Templates helper functions used within add_workflow_step. basic ones provided slurmworkflow package. instruct workflow run either bash script, set bash lines given character vector R script. Additional Step Templates can created simplify specific tasks. easiest way wrappers around existing templates.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":null,"dir":"Reference","previous_headings":"","what":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"Step template run sims result swfcalib calibration","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"","code":"step_tmpl_netsim_swfcalib_output(   path_to_x,   param,   init,   control,   calib_object,   n_rep,   n_cores,   output_dir,   libraries = NULL,   setup_lines = NULL,   max_array_size = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"path_to_x Path Fitted network model object saved saveRDS. (See x argument EpiModel::netsim function) param Model parameters, object class param.net. init Initial conditions, object class init.net. control Control settings, object class control.net. calib_object formatted calibration object n_rep number replication run scenario. n_cores number CPUs simulations run. output_dir folder simulation files stored. libraries character vector containing name libraries required model run. (e.g. EpiModelHIV EpiModelCOVID) setup_lines (optional) vector bash lines run first. can used load required modules (like R, python, etc). max_array_size maximum number array jobs submitted time. strictly less maximum number jobs allowed submit slurm HPC.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":"checkpointing","dir":"Reference","previous_headings":"","what":"Checkpointing","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"function takes care editing .checkpoint.dir create unique sub directories scenario. EpiModel::control.net way setting checkpoints can used transparently.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_netsim_swfcalib_output.html","id":"step-template","dir":"Reference","previous_headings":"","what":"Step Template","title":"Step template to run sims with the result of an swfcalib calibration — step_tmpl_netsim_swfcalib_output","text":"Step Templates helper functions used within add_workflow_step. basic ones provided slurmworkflow package. instruct workflow run either bash script, set bash lines given character vector R script. Additional Step Templates can created simplify specific tasks. easiest way wrappers around existing templates.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_renv_restore.html","id":null,"dir":"Reference","previous_headings":"","what":"Step template to update a project renv — step_tmpl_renv_restore","title":"Step template to update a project renv — step_tmpl_renv_restore","text":"template makes step run git pull renv::restore(). help ensure project date running rest workflow. See slurmworkflow::step_tmpl_bash_lines details step templates","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_renv_restore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Step template to update a project renv — step_tmpl_renv_restore","text":"","code":"step_tmpl_renv_restore(git_branch, setup_lines = NULL, lockfile = NULL)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_renv_restore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Step template to update a project renv — step_tmpl_renv_restore","text":"git_branch git branch project supposed follow. project following right branch, step error. setup_lines (optional) vector bash lines run first. can used load required modules (like R, python, etc). lockfile (optional) path alternative lockfile restore","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/step_tmpl_renv_restore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Step template to update a project renv — step_tmpl_renv_restore","text":"template function used add_workflow_step","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_hyak.html","id":null,"dir":"Reference","previous_headings":"","what":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","title":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","text":"Preset Configuration HYAK Cluster","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_hyak.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","text":"","code":"swf_configs_hyak(   hpc = \"klone\",   partition = \"csde\",   r_version = \"4.2.2\",   mail_user = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_hyak.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","text":"hpc HPC use HYAK (either \"klone\" \"mox\") partition partition use HYAK (either \"csde\" \"ckpt\") r_version version R load mail_user mail address send messages , default NULL (see 'sbatch –mail-type' argument)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_hyak.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","text":"list containing default_sbatch_opts, renv_sbatch_opts r_loader (see \"hpc_configs\" section)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_hyak.html","id":"hpc-configs","dir":"Reference","previous_headings":"","what":"hpc_configs","title":"Preset of Configuration for the HYAK Cluster — swf_configs_hyak","text":"default_sbatch_opts list sbatch options passed slurmworkflow::create_workflow. renv_sbatch_opts list sbatch options passed slurmworkflow::step_tmpl_renv_restore. provides sane defaults building dependencies R project using renv r_loader set bash lines make R software available. passed setup_lines arguments slurmworkflow::step_tmpl_ functions requires .","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_rsph.html","id":null,"dir":"Reference","previous_headings":"","what":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","title":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","text":"Preset Configuration RSPH Cluster","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_rsph.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","text":"","code":"swf_configs_rsph(   partition = \"preemptable\",   r_version = \"4.2.1\",   git_version = \"2.35.1\",   mail_user = NULL )"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_rsph.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","text":"partition partition use RSPH (either \"compute\" \"epimodel\") r_version version R load git_version version Git load mail_user mail address send messages , default NULL (see 'sbatch –mail-type' argument)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_rsph.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","text":"list containing default_sbatch_opts, renv_sbatch_opts r_loader (see \"hpc_configs\" section)","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swf_configs_rsph.html","id":"hpc-configs","dir":"Reference","previous_headings":"","what":"hpc_configs","title":"Preset of Configuration for the RSPH Cluster — swf_configs_rsph","text":"default_sbatch_opts list sbatch options passed slurmworkflow::create_workflow. renv_sbatch_opts list sbatch options passed slurmworkflow::step_tmpl_renv_restore. provides sane defaults building dependencies R project using renv r_loader set bash lines make R software available. passed setup_lines arguments slurmworkflow::step_tmpl_ functions requires .","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swfcalib_proposal_to_scenario.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert an swfcalib Proposal into an EpiModel Scenario — swfcalib_proposal_to_scenario","title":"Convert an swfcalib Proposal into an EpiModel Scenario — swfcalib_proposal_to_scenario","text":"Convert swfcalib Proposal EpiModel Scenario","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swfcalib_proposal_to_scenario.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert an swfcalib Proposal into an EpiModel Scenario — swfcalib_proposal_to_scenario","text":"","code":"swfcalib_proposal_to_scenario(proposal, id = NULL)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swfcalib_proposal_to_scenario.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert an swfcalib Proposal into an EpiModel Scenario — swfcalib_proposal_to_scenario","text":"proposal swfcalib formatted proposal id .scenario.id scenario. NULL, use .proposal_index \"default\" former NULL well.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/swfcalib_proposal_to_scenario.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert an swfcalib Proposal into an EpiModel Scenario — swfcalib_proposal_to_scenario","text":"EpiModel scenario","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/verbose.hpc.net.html","id":null,"dir":"Reference","previous_headings":"","what":"Custom Progress Print Module for HPC Workflow — verbose.hpc.net","title":"Custom Progress Print Module for HPC Workflow — verbose.hpc.net","text":"function prints progress stochastic network models simulated netsim console txt file.","code":""},{"path":"http://epimodel.github.io/EpiModelHPC/reference/verbose.hpc.net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Custom Progress Print Module for HPC Workflow — verbose.hpc.net","text":"","code":"verbose.hpc.net(x, type, s = 1, at = 2)"},{"path":"http://epimodel.github.io/EpiModelHPC/reference/verbose.hpc.net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Custom Progress Print Module for HPC Workflow — verbose.hpc.net","text":"x type \"startup\", object class control.net, otherwise master data object netsim simulations. type Progress type, either \"startup\" starting messages simulations, \"progress\" time step specific messages. s Current simulation number, type \"progress\". Current time step, type \"progress\".","code":""}]
