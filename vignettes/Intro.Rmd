---
title: "EpiModel.hpc: EpiModel for High-Performance Computing"
author: "Samuel M. Jenness"
date: "Department of Epidemiology, University of Washington"
output:
  html_document:
    theme: cerulean
---
<!--
%\VignetteEngine{knitr::rmarkdown}
%\VignetteIndexEntry{EpiModel.hpc Tutorial}
-->

<br>


## 1. Introduction
The **EpiModel.hpc** package is a set of high-performance computing (HPC) extensions to **EpiModel**  (http://epimodel.org). **EpiModel** is an **R** package that provides tools for the simulation of mathematical models of epidemics, including stochastic network models based on the statistical framework of temporal exponential random graph models (ERGMs). HPC systems may be needed for research-level modeling over networks in this framework because ERGM-based model estimation and simulation can bel computationally intensive with respect to both CPU and memory utilization. 

This tutorial provides background and examples of how to use **EpiModel.hpc** for research-level  simulations of network models. This software was designed to be run on Linux-based HPC systems with a Torque job scheduler that uses standard PBS-based shell scripts. However, components of this software package may be used in less complex systems, since the core functionality of **EpiModel.hpc** is based on parallelization of simulation jobs, which is possible on both thousand-node MPI-based clusters or a multicore laptop computer. The only difference is scale.

To get started, start by loading the **EpiModel.hpc** library:
```{r setup, eval=FALSE, message=FALSE}
library(EpiModel.hpc)
```

This package depends on **EpiModel** itself, so that package and the related [Statnet](http://statnet.org/) software suite will also be loaded. Readers without prior experience estimating and simulating network models in **EpiModel** should consult the [Basic Network Models](http://statnet.github.io/tut/BasicNet.html) tutorial first. This tutorial assumes readers are familiar with that material.


## 2. A Basic Simulation in Parallel
To get started, we demonstrate the **EpiModel.hpc** function `netsim_par`, which runs multiple simulations of stochastic network models in parallel. Such simulations would ordinarily be run sequentially with the **EpiModel** function `netsim`. 

The following code initializes a network and fits a basic edges-only (homogeneous mixing) ERGM using the `netest` function. The mean duration of edges is 50 time units, and the dissolution model is also homogeneous.
```{r basic1, eval=FALSE}
nw <- network.initialize(n = 1000, directed = FALSE)
formation <- ~ edges
target.stats <- 500
dissolution <- ~ offset(edges)
duration <- 50
coef.diss <- dissolution_coefs(dissolution, duration)
est <- netest(nw, formation, dissolution,
              target.stats, coef.diss)
```

The epidemic model will be of an susceptible-infected (SI) disease in an open population. This requires specifying parameters for the per-contact infection probability, the birth and death rates, and the initial number infected.
```{r basic2, eval=FALSE}
param <- param.net(inf.prob = 0.25, b.rate = 0.001, 
                   ds.rate = 0.001, di.rate = 0.001)
init <- init.net(i.num = 50)
```

The current goal is to simulate this model 10 times over 250 time steps. On an HPC system with at least 10 cores, it is possible to run all of these individual simulations in parallel. The total simulation time here even run sequentially is not so long, given the relatively small network size and number of time steps; this is just an example for much larger simulations.

The control settings look similar to standard settings for `control.net`, but with two additions: `par.type` and `ncores`. The `par.type` argument determines whether the simulation will be a single-node, multicore setup (`"single"`), versus a multiple-node setup with MPI (`"mpi"`). The single-node type will run on any computing system with multiple cores, whereas the multiple-node setup requires an MPI installation.
```{r basic3, eval=FALSE}
control <- control.net(type = "SI", nsteps = 250, verbose = FALSE,
                       nsims = 10, par.type = "single", ncores = 10)
```

To simulate the model in parallel, we use the `netsim_par` function instead of the `netsim` function in base **EpiModel**. All the setup for parallelization is be handled internally, and the output object `sim` may be plotted and analyzed just as one would for a sequential simulation.
```{r basic4, eval=FALSE}
sim <- netsim_par(est, param, init, control)
```

It is not expected that the code above be executed in interactive mode, in which commands are entered manually into the console window. Parallel simulations should be run in batch mode. The commands above could be placed into script named `sim1.R` and executed on the command line with:
```{r, basic5, eval=FALSE}
R CMD BATCH sim1.R
```

There are many variations and options to submitting batch jobs in R, which are outside the scope of this tutorial. The files for this simulation example may be found in this directory of your system.
```{r sf1, eval=FALSE}
system.file("examples", "basic", package = "EpiModel.hpc")
```


## 3. Parallelization with MPI
**EpiModel.hpc** supports parallelization of network models in an MPI system, in which data are passed between nodes in a cluster. While MPI systems may be set up in many ways, we demonstrate here a basic form useful epidemic simulations in **EpiModel**.

To use MPI on multiple nodes, we set the `par.type` argument accordingly in the `control.net` settings. This setup will allow for 25 simulations to be run in parallel across as many nodes as needed (the default MPI job distribution options will determine how this work is distributed across the nodes).
```{r mpi1, eval=FALSE}
control <- control.net(type = "SI", nsteps = 100, verbose = FALSE,
                       par.type = "mpi", nsims = 25, ncores = 25)
sim <- netsim_par(est, param, init, control)
```

The model may be simulating using the same function call as in a single-node parallelization, but the command line execution must use `mpirun`:
```{r mpi2, eval=FALSE}
mpirun -np 1 R --slave CMD BATCH --vanilla sim1.R
```

The files for this simulation example may be found in this directory of your system.
```{r sf2, eval=FALSE}
system.file("examples", "basicmpi", package = "EpiModel.hpc")
```


## 4. Job Submissions on Torque
Torque is a standard computational job scheduling software platform used by many scientific HPC systems. It has the benefit of a systematic resource allocation method for submitting large-scale simulation jobs. If your HPC is not running Torque, this section may not be relevant.

### A Starting Example
To run jobs via Torque, it is necessary to build three layers of scripts containing data commands. *Layer 1* is the underlying R script file to run the simulation, as demonstrated above. The following code chunk is one complete R script file, `sim1.R`, containing the source code to run the network model in parallel.
```{r sim1, eval=FALSE}
library(EpiModel.hpc)

nw <- network.initialize(n = 1000, directed = FALSE)
formation <- ~ edges
target.stats <- 500
dissolution <- ~ offset(edges)
duration <- 50
coef.diss <- dissolution_coefs(dissolution, duration)
est <- netest(nw, formation, dissolution,
              target.stats, coef.diss)

param <- param.net(inf.prob = 0.01)
init <- init.net(i.num = 50)
control <- control.net(type = "SI", nsteps = 250, verbose = FALSE,
                       par.type = "single", nsims = 10, ncores = 10)
                       
sim <- netsim_par(est, param, init, control)
save(sim, file = "sim.rda")
```

*Layer 2* is a shell script, called `runsim.sh`, that contains the Torque job directives along with the batch call to R. The Torque job specifications start with `#PBS`, and include elements like the resources needed, as defined in the `-l` directive, which may vary from HPC system to system. Our HPC system requires a spec for the number of nodes, processors per node, memory, and walltime (maximum processing time) for a job.
```{r runsim, eval=FALSE}
#!/bin/bash

### Specs
#PBS -N MyProject
#PBS -l nodes=1:ppn=16,mem=44gb,feature=16core,walltime=06:00:00
#PBS -o <standard output directory>
#PBS -e <standard error directory>
#PBS -d <data directory>
#PBS -m ae
#PBS -M <email address for notifications>

### Modules
module load r_3.1.1

### App
R CMD BATCH --vanilla sim1.R sim1.Rout
```

The software for R is loaded using the `module` command in the script. If using MPI, then the applicable MPI module would also need to be loaded. Finally, the R script is run using the `R CMD BATCH` method as demonstrated earlier. 

*Layer 3* is the command line job execution. One executes a Torque job scheduling request by using the `qsub` command with the shell script file name.
```{r qsub, eval=FALSE}
qsub runsim.sh
```

Note that this last layer can included in its own bash shell script if many of these qsub commands need to be run, rather than entering them manually.

The files for this simulation example may be found in this directory of your system.
```{r sf3, eval=FALSE}
system.file("examples", "torque", package = "EpiModel.hpc")
```


### Environmental Variables
If one has many different R script files to run, it may be easier to pass environment variables that are read through the software layers. Let's say, for example, that we have 3 different R scripts, each with different parameters, with the files named `sim1.R` to `sim3.R`, in sequence. In *Layer 3*, it is possible to run 3 calls to `qsub` using the `-v` argument to pass an environmental variable into `runsim.sh`.
```{r qsub2, eval=FALSE}
qsub -v SIMNO=1 runsim.sh
qsub -v SIMNO=2 runsim.sh
qsub -v SIMNO=3 runsim.sh
```

Then the *Layer 2* `runsim.sh` would be written as follows. A separate `runsim.sh` file is not needed to be edited for each R script file. This one shell script file can launch all 3 of those files R script files.
```{r runsim2, eval=FALSE}
#!/bin/bash

### Specs
#PBS -N sim$SIMNO
#PBS -l nodes=1:ppn=16,mem=44gb,feature=16core,walltime=06:00:00
#PBS -o <standard output directory>
#PBS -e <standard error directory>
#PBS -d <data directory>
#PBS -m ae
#PBS -M <email address for notifications>

### Modules
module load r_3.1.1

### App
R CMD BATCH --vanilla sim$SIMNO.R sim$SIMNO.Rout
```

The files for this simulation example may be found in this directory of your system.
```{r sf4, eval=FALSE}
system.file("examples", "envvars", package = "EpiModel.hpc")
```


### Array Jobs
Given some memory complications with MPI, we have found it more efficient to run some large-scale simulations using several calls to the same R script file. For example, instead of running one 100-simulation job on 7 16-core nodes, it is possible to run 7 sub-jobs and then merge the data externally at the end. This is facilitated with array jobs specifications in Torque. To do this in our example, it is necessary to edit all three layers of the software.

In *Layer 3*, one would now execute the qsub function with a `-t` parameter. This tells `qsub` to execute the `runsim.sh` file over multiple instances, 7 times in our case.
```{r qsub3, eval=FALSE}
qsub -t 1-7 -v SIMNO=1 runsim.sh
```

In the *Layer 2* `runsim.sh` file, one uses this `-t` parameter data as follows. The final line in `runsim.sh` would now call on the `PBS_ARRAYID` environmental variable, which is what the `-t` argument sets in the layer above. This variable and the `SIMNO` variable are then used to reference input and output. The command below also passes an environmental variable down into the R script with the `-$SIMNO.${PBS_ARRAYID}` input: this would have the effect of passing a simulation number of 1.1 down for the first instance, 1.2 for the second, and so on.
```{r runsim3, eval=FALSE}
R CMD BATCH --vanilla -$SIMNO.${PBS_ARRAYID} sim$SIMNO.R sim$SIMNO.${PBS_ARRAYID}.Rout
```

In the *Layer 1* R script file, `sim1.R`, we pull that environmental variable and feed it into the control settings. The `commandArgs` processes that variable and we then input it as an argument into `control.net`.
```{r rscript3, eval=FALSE}
library(EpiModel.hpc)

args <- commandArgs(FALSE)
args <- args[length(args)]
fsimno <- sub("-", "", args)
print(fsimno)

nw <- network.initialize(n = 1000, directed = FALSE)
formation <- ~ edges
target.stats <- 500
dissolution <- ~ offset(edges)
duration <- 50
coef.diss <- dissolution_coefs(dissolution, duration)
est <- netest(nw, formation, dissolution,
              target.stats, coef.diss)

param <- param.net(inf.prob = 0.01)
init <- init.net(i.num = 50)
control <- control.net(simno = fsimno,
                       type = "SI", nsteps = 250, verbose = FALSE,
                       par.type = "single", nsims = 10, ncores = 10)
                       
sim <- netsim_par(est, param, init, control)
savesim(sim)
```

Once the simulation has completed, we use the `savesim` function to save the Rdata file containing the `sim` object in a standardized way that includes a time-stamp on the file and also the reference to the `simno` passed down from the top.

Note that this sort of array specification could also have been used to execute the 3 R script files, if instead of using the `PBS_ARRAYID` variable to create a subjob ID, we used it in place of the `SIMNO` environmental variable we had passed down with the `-v` parameter.

The files for this simulation example may be found in this directory of your system.
```{r sf5, eval=FALSE}
system.file("examples", "array", package = "EpiModel.hpc")
```


## 5. Checkpointing
Checkpointing is the practice of incrementally saving data to disk for the purposes of reloading it in the case that a simulation job is canceled and restarted. Canceling and restarting occurs on our HPC system reguarly when using a "backfill queue": one may execute jobs to run over the entire HPC system, not just the nodes that are owned by our local research group, but the "catch" is that when the owners of those nodes submit jobs on them, one's backfill job is preempted. Preemption means that a job is canceled, requeued, and restarts in the next available backfill slot. Checkpointing is required so that when preemption happens, a job restarts not at time 0 but at some intermediate time point.

There are many different methods for checkpointing, but we have designed one specifically for **EpiModel** given its use of time-series data in which a simulation may be restarted where it stopped at any time step. The processes of checkpointing in **EpiModel** is defined in the function `netsim_hpc`. 

Briefly, `netsim_hpc` wraps `netsim_par` to run parallel simulations with checkpointing. Within the workflow of the simulation, `netsim_hpc` inserts a module that saves the data after every 100 time steps (this may be changed with a `save.int` control setting). The data structure for this intermediate data will be created when the function runs. When a simulation job starts, `netsim_par` will check for the presence of any checkpointed data, and if it is there, will restart the simulation from it. If no checkpointed data exist (as in the first time running `netsim_hpc`), the simulation will start from time 0. Once the simulation has completed, the checkpoint data structure will be deleted.

To use this form of checkpointing, simply replace the call to `netsim_par` with a similar call to `netsim_hpc`. The first argument now must be a character vector with the file location of the fitted network model object (the output of `netest`). Additionally, instead of assinging this to a `sim` data element and then saving it using `save`, `netsim_hpc` handles all of this internally using the `savesim` function as demonstrated above.
```{r netsimhpc, eval=FALSE}
netsim_hpc("est.rda", param, init, control)
```

Checkpointing may be useful even in HPC systems in which there is little chance of routine job preemption. It allows for restarting of long-running simulations that may have stopped due to internal software errors or related issues. If one is not concerned about checkpointing, however, it may be more straightforward to use the `netsim_par` function directly.

The files for this simulation example may be found in this directory of your system.
```{r sf6, eval=FALSE}
system.file("examples", "checkpoint", package = "EpiModel.hpc")
```


<br>